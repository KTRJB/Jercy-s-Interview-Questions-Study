# 프로세스

## 1. 프로세스 기본 개념

### 1.1 프로세스란?

실행 중인 프로그램을 의미합니다. 정적인 프로그램이 메모리에 적재되어 동적으로 실행되는 것을 말합니다.

쉬운 예시:

- 워드 프로그램이 하드디스크에 설치되어 있을 때는 그냥 프로그램
- 워드를 실행하면 그때부터 프로세스가 됨
- 워드를 여러 개 실행하면 여러 개의 프로세스가 생성됨

### 1.2 프로세스 구조

메모리에서 프로세스는 다음과 같은 영역을 가집니다:

1. 코드 영역 (Text Section)
    - 실행할 프로그램의 코드가 저장되는 영역
    - 읽기 전용으로 수정 불가
    - 여러 프로세스가 공유 가능
2. 데이터 영역 (Data Section)
    - 전역 변수, static 변수 저장
    - 프로그램이 시작될 때 할당되고 종료될 때 해제
    - 예: int globalVar = 0;
3. 힙 영역 (Heap)
    - 동적으로 할당되는 메모리 영역
    - 프로그래머가 직접 관리 (malloc/free)
    - 예: 동적 배열, 링크드 리스트 등
4. 스택 영역 (Stack)
    - 함수 호출과 관련된 정보 저장
    - 지역 변수, 매개변수 저장
    - 함수 호출 시 생성되고 반환 시 자동으로 제거

## 2. 프로세스 상태

### 2.1 프로세스의 5가지 상태

1. 생성 상태 (New)
    - 프로세스가 막 생성된 상태
    - 초기화 작업 진행 중
    - 예: 프로그램 아이콘을 더블클릭한 직후
2. 준비 상태 (Ready)
    - CPU를 할당받을 수 있는 상태
    - 실행 준비가 완료된 상태
    - 예: 메모리에 로드되어 실행 대기 중
3. 실행 상태 (Running)
    - CPU를 할당받아 실제 실행 중인 상태
    - 한 시점에 CPU당 하나의 프로세스만 실행 가능
    - 예: 현재 워드에서 타이핑 중일 때
4. 대기 상태 (Blocked/Wait)
    - I/O 작업 등을 기다리는 상태
    - CPU를 할당받아도 실행할 수 없음
    - 예: 파일 저장을 기다리는 중
5. 종료 상태 (Terminated)
    - 프로세스 실행이 완료된 상태
    - 사용된 자원 정리 중
    - 예: 프로그램의 'X' 버튼을 눌러 종료할 때

### 2.2 상태 전이가 발생하는 경우

1. Ready → Running
    - CPU 스케줄러가 이 프로세스를 선택할 때
    - 이전 프로세스가 종료되거나 대기 상태로 갈 때
2. Running → Ready
    - 더 높은 우선순위의 프로세스가 등장할 때
    - CPU 할당 시간이 끝났을 때
3. Running → Blocked
    - I/O 요청이 발생했을 때
    - 자원을 기다려야 할 때
    - 예: 프린터 출력 요청
4. Blocked → Ready
    - I/O 작업이 완료되었을 때
    - 요청한 자원을 받았을 때

## 3. 프로세스 제어 블록 (PCB)

### 3.1 PCB란?

- 운영체제가 프로세스를 관리하기 위해 유지하는 정보 구조체
- 프로세스의 중요 정보를 보관
- 프로세스 생성 시 생성되고 종료 시 삭제됨

### 3.2 PCB에 저장되는 정보

1. 프로세스 식별 정보
    - Process ID (PID)
    - Parent Process ID (PPID)
        - 모든 프로세스는 다른 프로세스에 의해 생성됨
        - 최초의 프로세스(init 또는 systemd)만 예외
    - User ID
2. 프로세스 상태 정보
    - 현재 프로세스의 상태
    - 우선순위
    - 스케줄링 관련 정보
3. 프로세스 제어 정보
    - 프로그램 카운터 값
    - CPU 레지스터 값
    - 메모리 관리 정보
    - 입출력 상태 정보

## 4. 프로세스 스케줄링

### 4.1 스케줄링이란?

- 여러 프로세스가 CPU를 효율적으로 사용할 수 있도록 관리하는 기법
- CPU 사용 시간을 프로세스들에게 분배하는 방법을 결정
- 시스템의 전반적인 성능에 직접적인 영향을 미침

### 4.2 스케줄링 알고리즘 종류

1. FCFS (First Come First Served)
    - 가장 먼저 도착한 프로세스를 먼저 처리
    - 장점: 구현이 간단, 공평함
    - 단점: 짧은 프로세스가 긴 프로세스를 기다려야 할 수 있음
    - 예: 은행 번호표 순서대로 처리
2. SJF (Shortest Job First)
    - 실행 시간이 가장 짧은 프로세스 먼저 실행
    - 장점: 평균 대기 시간 최소화
    - 단점: 긴 프로세스는 계속 미뤄질 수 있음
    - 예: 계산대에서 물건 적은 사람 먼저 처리
3. Round Robin
    - 각 프로세스에 동일한 CPU 시간 할당
    - 할당 시간 종료되면 다음 프로세스로 전환
    - 장점: 공평한 자원 분배
    - 예: 회전문처럼 돌아가면서 처리
    - 단점: 문맥 교환 오버헤드
        - 잦은 문맥 교환 발생
        - CPU 시간 낭비
        - 캐시 효율성 저하
        1. 타임 퀀텀 설정의 어려움
            - 너무 크면 FCFS와 비슷
            - 너무 작으면 문맥 교환 오버헤드 증가
            - 적절한 값 설정이 중요
        2. 프로세스 특성 미고려
            - CPU 집중 프로세스와 I/O 집중 프로세스 구분 없음
            - 동일한 시간 할당으로 인한 비효율
        3. 평균 반환 시간 증가
            - 긴 작업의 경우 완료까지 시간 증가
            - 전체적인 처리량 감소 가능성

## 5. 프로세스 간 통신 IPC(**Inter-process communication)**

### 5.1 IPC가 필요한 이유

- 프로세스 간 데이터 공유
- 계산 속도 향상을 위한 작업 분할
- 모듈화를 통한 시스템 기능 분리
- 예: 웹 브라우저와 미디어 플레이어 간의 통신

### 5.2 IPC 방식

1. 공유 메모리 (Shared Memory)
    - 여러 프로세스가 동일한 메모리 영역 공유
    - 장점: 빠른 통신 속도
    - 단점: 동기화 필요
    - 예: 데이터베이스 시스템의 캐시 공유
2. 메시지 전달 (Message Passing)
    - 프로세스 간 메시지를 주고받음
    - 운영체제가 통신을 관리
    - 예: 클라이언트-서버 통신
3. 파이프 (Pipe)
    - 한 프로세스의 출력을 다른 프로세스의 입력으로 연결
    - 주로 부모-자식 프로세스 간 통신에 사용
    - 예: Unix의 파이프 명령어 (|)

## 6. 프로세스 동기화

### 6.1 동기화가 필요한 이유

- 공유 자원에 대한 접근 제어
- 데이터 일관성 유지
- 프로세스 실행 순서 제어
- 예: 두 프로세스가 동시에 프린터 사용 시 충돌 방지

### 6.2 동기화 메커니즘

1. 뮤텍스 (Mutex)
    - 상호 배제를 위한 잠금 메커니즘
    - 한 번에 하나의 프로세스만 접근 가능
    - 예: 화장실 사용 중 잠금장치
2. 세마포어 (Semaphore)
    - 여러 프로세스의 접근을 제어
    - 카운터를 통한 접근 제한
    - 예: 주차장 입구의 차단기
3. 모니터 (Monitor)
    - 높은 수준의 동기화 메커니즘
    - 조건 변수를 통한 프로세스 제어
    - 예: 은행의 창구 시스템

## 7. 교착상태 (Deadlock)

### 7.1 교착상태란?

- 두 개 이상의 프로세스가 서로가 가진 자원을 기다리며 블록된 상태
- 어떤 프로세스도 진행할 수 없는 상황
- 예: 식당에서 두 사람이 서로의 젓가락을 기다리는 상황

### 7.2 교착상태 발생 조건

1. 상호 배제
    - 자원은 한 번에 하나의 프로세스만 사용 가능
2. 점유와 대기
    - 자원을 가진 상태에서 다른 자원을 요청
3. 비선점
    - 다른 프로세스의 자원을 강제로 빼앗을 수 없음
4. 순환 대기
    - 프로세스들이 순환 형태로 자원을 기다림

## 8. 문맥 교환 (Context Switch)

### 8.1 문맥 교환이란?

- 현재 실행 중인 프로세스의 상태를 저장하고 다른 프로세스를 실행하기 위해 그 프로세스의 상태를 복원하는 작업
- CPU를 한 프로세스에서 다른 프로세스로 넘겨주는 과정

### 8.2 문맥 교환이 발생하는 경우

1. 인터럽트 발생 시
    - 하드웨어 인터럽트
    - 소프트웨어 인터럽트(시스템 콜)
2. 프로세스 스케줄링에 의해
    - CPU 사용 시간 만료
    - 우선순위가 높은 프로세스 등장
3. I/O 요청 발생 시
    - 프로세스가 I/O 작업을 요청할 때
    - I/O 작업 완료 시

### 8.3 문맥 교환 과정

1. 현재 프로세스의 상태 저장
    - PCB에 현재 상태 정보 저장
    - CPU 레지스터 값 저장
    - 프로그램 카운터 값 저장
2. 새로운 프로세스의 상태 복원
    - PCB에서 새 프로세스 정보 로드
    - CPU 레지스터 값 복원
    - 프로그램 카운터 값 복원

### 8.4 문맥 교환의 오버헤드

1. 직접적인 오버헤드
    - CPU 시간 소비
    - 메모리 사용
2. 간접적인 오버헤드
    - 캐시 무효화
    - TLB(Translation Lookaside Buffer) 플러시
        - 가상 주소를 물리 주소로 변환하는 캐시
        - 페이지 테이블의 캐시 역할
        - MMU(Memory Management Unit)의 일부
    - 파이프라인 플러시
        - CPU 명령어 처리를 여러 단계로 나누어 병렬 처리
        - 일반적으로 Fetch → Decode → Execute → Memory → Writeback 단계로 구성
        - 처리량 향상을 위한 구조

### 8.5 문맥 교환 최적화 방법

1. 스레드 사용
    - 같은 프로세스 내 스레드 간 문맥 교환은 비용이 적음
    - 메모리 주소 공간을 공유하므로 더 효율적
2. 프로세스 우선순위 조정
    - 불필요한 문맥 교환 감소
    - 중요 프로세스의 실행 보장

# 스레드(Thread)

## 1. 스레드의 기본 개념

스레드는 프로세스 내에서 실행되는 가장 작은 실행 단위입니다. 하나의 프로세스는 여러 개의 스레드를 가질 수 있으며, 각 스레드는 프로세스의 자원을 공유하면서 독립적으로 실행됩니다. '경량 프로세스'라고도 불립니다.

## 2. 프로세스와 스레드의 차이

프로세스는 독립적인 메모리 공간과 자원을 가지는 반면, 스레드는 프로세스의 자원을 공유합니다. 스레드는 프로세스보다 생성과 종료가 빠르며, 문맥 교환 비용이 적습니다.

## 3. 스레드가 공유하는 자원

- 코드 섹션
- 데이터 섹션
- 프로세스의 열린 파일이나 신호와 같은 운영체제 자원
- 힙 영역

## 4. 스레드의 고유 자원

- 스레드 ID
    - 각 스레드를 식별하는 고유한 식별자
- 프로그램 카운터
    - 다음에 실행할 명령어의 주소를 가리키는 레지스터
    - 명령어 실행 → PC 증가 → 다음 명령어 가리킴
    - 분기문 실행 시 해당 주소로 PC 변경
    - 인터럽트 발생 시 현재 PC 값 저장
- 레지스터 집합
    - CPU 내부의 고속 저장 장소
    - 스레드 실행에 필요한 정보 저장
    - 문맥 교환 시 저장/복원되는 정보
- 스택
    - 스레드 별로 할당되는 독립적인 메모리 영역
        1. 지역 변수
            - 함수 내부에서 선언된 변수
            - 함수 종료 시 자동 해제
        2. 매개변수
            - 함수 호출 시 전달되는 인자
            - 호출된 함수에서 접근 가능
        3. 반환 주소
            - 함수 호출 후 돌아갈 위치
            - 호출 순서 추적에 사용
        4. 스택 프레임
            - 함수 호출마다 생성
            - 지역 변수와 매개변수 포함
            - 함수의 실행 환경 관리

## 5. 스레드의 상태

- 생성(NEW): 스레드가 생성된 상태
- 실행 가능(RUNNABLE): CPU를 할당받을 수 있는 상태
- 실행(RUNNING): 실제 실행 중인 상태
- 차단(BLOCKED): I/O나 동기화 작업을 기다리는 상태
- 종료(TERMINATED): 실행이 완료된 상태

## 6. 스레드의 종류

### 사용자 수준 스레드

- 사용자 영역에서 관리되는 스레드
- 운영체제가 인식하지 못함
- 구현과 관리가 쉬움
- 하나의 스레드 블록 시 전체 프로세스가 블록됨
- iOS에서 NSThread

### 커널 수준 스레드

- 운영체제가 직접 관리하는 스레드
- 운영체제의 지원을 직접 받음
- 구현이 복잡하고 오버헤드가 큼
- 한 스레드가 블록되어도 다른 스레드는 실행 가능
- iOS에서 GCD, NSOperation

### 메인 스레드

- 프로그램 실행 시 가장 먼저 생성되는 스레드
- 프로세스의 시작점(main 함수)에서 실행되는 스레드
- 다른 스레드를 생성하고 관리할 수 있음
- 프로그램의 주요 실행 흐름을 담당
- 메인 스레드 종료 시 프로세스도 종료될 수 있음

## 7. 스레드 동기화

### 동기화가 필요한 이유

- 공유 자원에 대한 동시 접근 제어
- 데이터의 일관성 유지
- 실행 순서 제어

### 동기화 방법

- 뮤텍스: 상호 배제를 위한 잠금 매커니즘
- 세마포어: 공유 자원에 대한 접근을 카운팅
- 모니터: 상호 배제와 동기화를 위한 고수준 매커니즘
- 뮤텍스 VS 세마포어
    - 소유권
        - 뮤텍스: 잠금을 획득한 스레드만 해제 가능
        - 세마포어: 어느 스레드든 신호 전송 가능
    - 값의 범위
        - 뮤텍스: 0 또는 1
        - 세마포어: 0 이상의 정수값
    - 사용 목적
        - 뮤텍스: 공유 자원 접근 제어
        - 세마포어: 리소스 개수 관리 및 동기화
    - 동작 방식
        - 뮤텍스: lock/unlock 방식
        - 세마포어: wait(P)/signal(V) 방식

## 8. 멀티스레딩의 장점

- 응답성 향상
- 자원 공유를 통한 효율성
- 경제성 (스레드 생성이 프로세스보다 경제적)
- 멀티프로세서 활용 가능

## 9. 멀티스레딩의 단점

- 동기화 이슈
- 데드락 가능성
- 디버깅의 어려움
- 스레드 안전성 확보 필요

## 10. 스레드 풀

- 미리 생성된 스레드들의 집합
- 작업 요청 시 스레드를 재사용
- 스레드 생성/소멸 비용 절감
- 시스템 자원 관리 용이

## 11. 스레드 스케줄링

- 우선순위 기반 스케줄링
- 라운드 로빈 스케줄링
- 실시간 스케줄링

## 12. 스레드 안전성

### 1. 재진입성(Reentrancy) 보장

### 의미

- 동일한 코드가 여러 스레드에서 동시에 실행 가능한 특성
- 한 스레드의 실행이 다른 스레드에 영향을 주지 않음

### 보장 방법

- 공유 자원 사용 최소화
- 지역 변수 사용
- 상태를 변경하지 않는 순수 함수 작성
- 스레드별 독립적인 스택 활용

### 2. 원자성(Atomicity) 보장

### 의미

- 연산이 중간에 끊기지 않고 완전히 실행되거나 전혀 실행되지 않음
- 작업의 완전성 보장

### 보장 방법

- 원자적 연산 사용
- 락(Lock) 메커니즘 활용
- 트랜잭션 처리
- Critical Section 보호

### 3. 가시성(Visibility) 보장

### 의미

- 한 스레드의 변경사항이 다른 스레드에 즉시 보이도록 함
- 캐시와 메인 메모리 간의 동기화 보장

### 보장 방법

- volatile 키워드 사용
- 메모리 배리어 사용
- 동기화 메커니즘 활용
- 적절한 캐시 관리

### 4. 순서성(Ordering) 보장

### 의미

- 프로그램이 작성된 순서대로 실행됨을 보장
- 컴파일러나 CPU의 재배치 최적화 제어

### 보장 방법

- 동기화 메커니즘 사용
- 메모리 배리어 삽입
- happens-before 관계 설정
- 적절한 의존성 관리

### 실제 적용 사례

### 재진입성

- 수학 연산 함수
- 유틸리티 메서드
- 상태를 변경하지 않는 조회 함수

### 원자성

- 계좌 잔액 업데이트
- 카운터 증가/감소
- 데이터베이스 트랜잭션

### 가시성

- 공유 플래그 변수
- 상태 변수
- 종료 신호

### 순서성

- 초기화 순서
- 이벤트 처리 순서
- 데이터 의존성이 있는 연산

### 동시성 문제 해결 전략

### 1. 상태 관리

- 불변 객체 사용
- 상태 변경 최소화
- 스레드 로컬 변수 활용

### 2. 동기화 메커니즘

- 락 사용
- 원자적 연산
- 메모리 배리어

### 3. 설계 원칙

- 단일 책임 원칙
- 불변성 활용
- 명확한 소유권 정의

### 4. 테스트

- 동시성 테스트
- 스트레스 테스트
- 경쟁 조건 테스트

# iOS의 프로세스와 스레드 관리

## 1. iOS 프로세스 특징

### 기본 특성

- 하나의 앱은 하나의 프로세스로 실행
- 샌드박스 환경에서 격리 실행
- 메모리와 시스템 자원 제한적 사용
- 백그라운드 제약 존재

### 생명주기

- Not Running: 실행되지 않은 상태
- Inactive: 실행 중이나 이벤트 미수신
- Active: 정상 실행 중
- Background: 백그라운드 실행
- Suspended: 백그라운드에서 일시 중지

## 2. iOS 스레드 관리

### 메인 스레드

- UI 업데이트 전용
- 사용자 이벤트 처리
- 빠른 응답성 필요
- 무거운 작업 지양

### 백그라운드 스레드

- 네트워크 작업
- 파일 I/O 처리
- 데이터베이스 작업
- 복잡한 연산 처리

## 3. 동시성 프로그래밍 도구

### GCD (Grand Central Dispatch)

- 시스템 레벨 스레드 관리
- 큐 기반 작업 처리
- 자동 스레드 풀 관리
- QoS(Quality of Service) 지원

### Operation Queue

- 객체 지향적 접근
- 작업 의존성 관리
- 작업 취소 기능
- KVO 지원

### NSThread

- 저수준 스레드 제어
- 직접적인 스레드 관리
- 사용 권장하지 않음

## 4. 큐(Queue) 종류

### Serial Queue

- 순차적 작업 실행
- 한 번에 하나의 작업만 처리
- 데이터 무결성 보장

### Concurrent Queue

- 동시 작업 실행
- 여러 작업 병렬 처리
- 처리량 향상

### Main Queue

- UI 업데이트 전용
- 메인 스레드에서 실행
- 직렬 큐 방식

## 5. QoS (Quality of Service)

### User Interactive

- 최고 우선순위
- 즉각적인 반응 필요
- UI 업데이트

### User Initiated

- 높은 우선순위
- 사용자 작업 응답
- 즉시 결과 필요

### Default

- 기본 우선순위
- 일반적인 작업

### Utility

- 낮은 우선순위
- 시간 소요 작업
- 진행 표시 필요

### Background

- 최저 우선순위
- 시간에 민감하지 않은 작업
- 에너지 효율 중시

## 6. 메모리 관리

### ARC (Automatic Reference Counting)

- 자동 메모리 관리
- 순환 참조 주의
- 캡처 리스트 활용

### 메모리 경고

- 시스템 메모리 부족 알림
- 불필요한 메모리 해제
- 중요 데이터 저장

## 7. 백그라운드 작업

### 백그라운드 실행 제약

- 제한된 실행 시간
- 특정 작업만 허용
- 시스템 리소스 제한

### 허용되는 백그라운드 작업

- 오디오 재생
- 위치 업데이트
- VoIP
- 네트워크 다운로드
- 백그라운드 페치

## 8. 성능 최적화

### 스레드 관리

- 적절한 큐 선택
- 작업 우선순위 설정
- 스레드 수 제한

### 리소스 관리

- 메모리 사용량 모니터링
- CPU 사용량 최적화
- 배터리 효율성 고려

# 멀티스레딩이 필요한 이유

## 1. 멀티스레딩이 필요한 이유

### 1.1 성능 향상

- 병렬 처리를 통한 처리 속도 개선
- CPU 자원의 효율적 활용
- 동시 작업 처리 가능

### 1.2 반응성 향상

- UI 응답성 유지
- 사용자 경험 개선
- 메인 스레드 블로킹 방지

### 1.3 리소스 활용

- 시스템 자원의 효율적 사용
- I/O 작업의 비동기 처리
- 네트워크 통신 최적화

### 1.4 작업 분리

- 독립적인 작업 동시 처리
- 복잡한 작업의 모듈화
- 코드 구조화 용이

# Grand Central Dispatch (GCD)

## 1. GCD 아키텍처

GCD는 Apple 플랫폼의 복잡한 동시성 문제를 효과적으로 해결할 수 있는 강력한 프레임워크

### 1.1 디스패치 큐(Dispatch Queue)

- FIFO(First In, First Out) 구조
- 작업의 순차적/병렬 실행 관리
- 스레드 안전성 보장
- 작업 실행 순서 제어

### 1.2 큐의 종류

1. Serial Queue (직렬 큐)
    - 순차적 작업 실행
    - 데이터 무결성 보장
    - 작업 순서 보장
2. Concurrent Queue (동시 큐)
    - 병렬 작업 실행
    - 동시성 최대화
    - 시스템이 실행 순서 결정
3. Main Queue
    - UI 작업 전용
    - 항상 메인 스레드에서 실행
    - 직렬 큐 방식

## 2. QoS (Quality of Service)

### 2.1 우선순위 레벨

1. userInteractive
    - 최고 우선순위
    - UI 업데이트, 애니메이션
    - 즉각적인 응답 필요
2. userInitiated
    - 높은 우선순위
    - 사용자 작업 응답
    - 데이터 로딩, 결과 표시
3. default
    - 기본 우선순위
    - 일반적인 작업
4. utility
    - 낮은 우선순위
    - 장시간 실행 작업
    - 계산, 다운로드 등
5. background
    - 최저 우선순위
    - 사용자에게 직접적 영향 없는 작업
    - 데이터 백업, 동기화

## 3. 작업 유형

### 3.1 동기 실행 (sync)

- 작업 완료까지 대기
- 순차적 실행 보장
- 데드락 주의 필요

### 3.2 비동기 실행 (async)

- 작업 완료 대기하지 않음
- 병렬 처리 가능
- 콜백으로 완료 처리

## 4. 디스패치 그룹

### 4.1 그룹 기능

- 여러 작업을 그룹으로 관리
- 작업 완료 동기화
- 의존성 관리
- 완료 알림 처리

## 5. Dispatch Work Item

### 5.1 특징

- 재사용 가능한 작업 단위
- 취소 가능
- 완료 핸들러 지정
- 우선순위 제어

## 6. 베리어(Barrier)

### 6.1 용도

- 동시성 제어
- 작업 순서 보장
- 데이터 일관성 유지
- 리소스 동기화

## 7. 세마포어

### 7.1 활용

- 동시 실행 제한
- 리소스 접근 제어
- 동기화 구현
- 임계 영역 보호
    - 베리어는 스레드 그룹의 동기화를 위해 사용되지만, 세마포어는 공유 자원에 대한 스레드의 접근을 제어하는 데 사용됩니다.
    - 베리어는 스레드 그룹이 특정 지점에 도달할 때까지 대기시키지만, 세마포어는 자원 가용성에 따라 스레드를 블록하거나 통과시킵니다.
    - 베리어는 스레드 그룹 내 모든 스레드가 동시에 진행되도록 보장하지만, 세마포어는 스레드 간 상호 배제를 제공합니다.

## 8. 성능 최적화

### 8.1 고려사항

- 적절한 큐 선택
- 작업 크기 최적화
- 우선순위 적절한 할당
- 리소스 사용 모니터링

### 8.2 권장 사항

- 장기 실행 작업 분할
- 적절한 QoS 레벨 사용
- 불필요한 직렬화 피하기
- 메인 큐 부하 최소화

## 9. 핵심적인 역할

### 동시성 처리 관리:

- 멀티코어 환경에서 효율적인 병렬 처리를 가능하게 함
- 디스패치 큐를 통해 작업의 순차적/병렬 실행을 제어

### 작업 우선순위 관리:

- QoS(Quality of Service) 레벨을 통해 작업의 중요도를 구분
- 사용자 상호작용이 필요한 작업부터 백그라운드 작업까지 우선순위 적용

### 리소스 동기화 및 보호:

- 베리어와 세마포어를 통해 공유 리소스에 대한 동시 접근을 제어
- 데이터 일관성 유지 및 임계 영역 보호

### 작업 그룹화 및 의존성 관리:

- 디스패치 그룹을 통해 관련된 작업들을 묶어 관리
- 작업 간 의존성을 정의하고 동기화 처리

### 성능 최적화:

- 적절한 큐 선택, 작업 크기 조정, 우선순위 할당 등으로 시스템 성능 향상
- 메인 큐 부하 최소화, 불필요한 직렬화 회피 등의 best practice 적용
